import json
import asyncio
import time
from core.providers.tts.dto.dto import SentenceType
from core.utils.util import get_string_no_punctuation_or_emoji, analyze_emotion
from loguru import logger

TAG = __name__

emoji_map = {
    "neutral": "ğŸ˜¶",
    "happy": "ğŸ™‚",
    "laughing": "ğŸ˜†",
    "funny": "ğŸ˜‚",
    "sad": "ğŸ˜”",
    "angry": "ğŸ˜ ",
    "crying": "ğŸ˜­",
    "loving": "ğŸ˜",
    "embarrassed": "ğŸ˜³",
    "surprised": "ğŸ˜²",
    "shocked": "ğŸ˜±",
    "thinking": "ğŸ¤”",
    "winking": "ğŸ˜‰",
    "cool": "ğŸ˜",
    "relaxed": "ğŸ˜Œ",
    "delicious": "ğŸ¤¤",
    "kissy": "ğŸ˜˜",
    "confident": "ğŸ˜",
    "sleepy": "ğŸ˜´",
    "silly": "ğŸ˜œ",
    "confused": "ğŸ™„",
}


async def sendAudioMessage(conn, sentenceType, audios, text):
    # å‘é€å¥å­å¼€å§‹æ¶ˆæ¯
    conn.logger.bind(tag=TAG).info(f"å‘é€éŸ³é¢‘æ¶ˆæ¯: {sentenceType}, {text}")
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯ASRé”™è¯¯ï¼Œå¦‚æœæ˜¯åˆ™ä¸å‘é€TTSå’Œæ–‡å­—
    if text is not None:
        asr_error_indicators = [
            "æ£€æµ‹åˆ°ASRè¯†åˆ«å¯èƒ½å‡ºé”™",
            "å†…å®¹ä¸å®Œæ•´ä¸”æ— æ˜ç¡®æ„å›¾",
            "ä¿æŒé™é»˜ç­‰å¾…ç”¨æˆ·ç»§ç»­è¾“å…¥",
            "æ— æ³•ç†è§£æ‚¨çš„è¾“å…¥",
            "è¯·é‡æ–°è¯´ä¸€é"
        ]
        
        # æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«ASRé”™è¯¯æŒ‡ç¤º
        is_asr_error = any(indicator in text for indicator in asr_error_indicators)
        
        # æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åªåŒ…å«æ— æ„ä¹‰çš„å­—ç¬¦ï¼ˆå¦‚"ê·¸"ã€"ä¹Ÿ"ç­‰å•å­—ï¼‰
        if len(text.strip()) <= 2 and not is_asr_error:
            is_asr_error = True
        
        if is_asr_error:
            conn.logger.bind(tag=TAG).info(f"æ£€æµ‹åˆ°ASRé”™è¯¯ï¼Œä¸å‘é€TTSå’Œæ–‡å­—: {text}")
            # æ¸…ç©ºTTSé˜Ÿåˆ—ï¼Œä¸æ’­æ”¾ä»»ä½•éŸ³é¢‘
            if sentenceType == SentenceType.LAST:
                conn.client_is_speaking = False
                if conn.close_after_chat:
                    await conn.close()
            return
    
    if text is not None:
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨è¡¨æƒ…å‘é€
        enable_emoji = conn.config.get("enable_emoji", True)
        if enable_emoji:
            emotion = analyze_emotion(text)
            emoji = emoji_map.get(emotion, "ğŸ™‚")  # é»˜è®¤ä½¿ç”¨ç¬‘è„¸
            await conn.websocket.send(
                json.dumps(
                    {
                        "type": "llm",
                        "text": emoji,
                        "emotion": emotion,
                        "session_id": conn.session_id,
                    }
                )
            )
    pre_buffer = False
    if conn.tts.tts_audio_first_sentence and text is not None:
        conn.logger.bind(tag=TAG).info(f"å‘é€ç¬¬ä¸€æ®µè¯­éŸ³: {text}")
        conn.tts.tts_audio_first_sentence = False
        pre_buffer = True

    await send_tts_message(conn, "sentence_start", text)

    await sendAudio(conn, audios, pre_buffer)

    await send_tts_message(conn, "sentence_end", text)

    # å‘é€ç»“æŸæ¶ˆæ¯ï¼ˆå¦‚æœæ˜¯æœ€åä¸€ä¸ªæ–‡æœ¬ï¼‰
    if conn.llm_finish_task and sentenceType == SentenceType.LAST:
        await send_tts_message(conn, "stop", None)
        conn.client_is_speaking = False
        if conn.close_after_chat:
            await conn.close()


# æ’­æ”¾éŸ³é¢‘
async def sendAudio(conn, audios, pre_buffer=True):
    if audios is None or len(audios) == 0:
        return
    
    # æµæ§å‚æ•°ä¼˜åŒ–
    frame_duration = 60  # å¸§æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰ï¼ŒåŒ¹é… Opus ç¼–ç 
    start_time = time.perf_counter()
    play_position = 0
    
    # å¯¹äºé•¿éŸ³é¢‘ï¼ˆå¦‚éŸ³ä¹æ–‡ä»¶ï¼‰ï¼Œç¦ç”¨é¢„ç¼“å†²
    # é˜ˆå€¼ï¼šè¶…è¿‡ 100 å¸§è®¤ä¸ºæ˜¯é•¿éŸ³é¢‘ï¼ˆçº¦ 6 ç§’ï¼‰
    is_long_audio = len(audios) > 100
    if is_long_audio:
        pre_buffer = False
        conn.logger.bind(tag=TAG).info(f"æ£€æµ‹åˆ°é•¿éŸ³é¢‘({len(audios)}å¸§)ï¼Œç¦ç”¨é¢„ç¼“å†²")

    # ä»…å½“ç¬¬ä¸€å¥è¯æ—¶æ‰§è¡Œé¢„ç¼“å†²
    if pre_buffer:
        pre_buffer_frames = min(3, len(audios))
        for i in range(pre_buffer_frames):
            await conn.websocket.send(audios[i])
        remaining_audios = audios[pre_buffer_frames:]
    else:
        remaining_audios = audios

    # æ’­æ”¾å‰©ä½™éŸ³é¢‘å¸§
    total_frames = len(remaining_audios)
    sent_frames = 0
    
    for opus_packet in remaining_audios:
        if conn.client_abort:
            conn.logger.bind(tag=TAG).info(f"å®¢æˆ·ç«¯ä¸­æ–­ï¼Œåœæ­¢å‘é€éŸ³é¢‘ï¼ˆå·²å‘é€{sent_frames}/{total_frames}å¸§ï¼‰")
            break

        # é‡ç½®æ²¡æœ‰å£°éŸ³çš„çŠ¶æ€
        conn.last_activity_time = time.time() * 1000

        # è®¡ç®—é¢„æœŸå‘é€æ—¶é—´
        expected_time = start_time + (play_position / 1000)
        current_time = time.perf_counter()
        delay = expected_time - current_time
        
        # ä¼˜åŒ–æµæ§é€»è¾‘ï¼š
        # 1. é™åˆ¶æœ€å¤§å»¶è¿Ÿæ—¶é—´ï¼Œé¿å…é•¿æ—¶é—´é˜»å¡
        # 2. å¯¹äºé•¿éŸ³é¢‘ï¼Œå‡å°‘å»¶è¿Ÿæ—¶é—´ï¼ŒåŠ å¿«å‘é€é€Ÿåº¦
        max_delay = 0.1 if is_long_audio else 0.5  # é•¿éŸ³é¢‘æœ€å¤§å»¶è¿Ÿ100msï¼ŒçŸ­éŸ³é¢‘500ms
        if delay > max_delay:
            delay = max_delay
        if delay > 0:
            await asyncio.sleep(delay)

        try:
            await conn.websocket.send(opus_packet)
            sent_frames += 1
            
            # å¯¹äºé•¿éŸ³é¢‘ï¼Œæ¯å‘é€ 100 å¸§è®°å½•ä¸€æ¬¡è¿›åº¦
            if is_long_audio and sent_frames % 100 == 0:
                conn.logger.bind(tag=TAG).info(f"éŸ³é¢‘å‘é€è¿›åº¦: {sent_frames}/{total_frames}å¸§ ({sent_frames*100//total_frames}%)")
        except Exception as e:
            conn.logger.bind(tag=TAG).error(f"å‘é€éŸ³é¢‘å¸§å¤±è´¥ï¼ˆç¬¬{sent_frames}å¸§ï¼‰: {e}")
            break

        play_position += frame_duration
    
    if sent_frames == total_frames:
        conn.logger.bind(tag=TAG).info(f"éŸ³é¢‘å‘é€å®Œæˆ: {sent_frames}å¸§ï¼Œè€—æ—¶{time.perf_counter()-start_time:.2f}ç§’")


async def send_tts_message(conn, state, text=None):
    """å‘é€ TTS çŠ¶æ€æ¶ˆæ¯"""
    message = {"type": "tts", "state": state, "session_id": conn.session_id}
    if text is not None:
        message["text"] = text

    # TTSæ’­æ”¾ç»“æŸ
    if state == "stop":
        # æ’­æ”¾æç¤ºéŸ³
        tts_notify = conn.config.get("enable_stop_tts_notify", False)
        if tts_notify:
            stop_tts_notify_voice = conn.config.get(
                "stop_tts_notify_voice", "config/assets/tts_notify.mp3"
            )
            audios, _ = conn.tts.audio_to_opus_data(stop_tts_notify_voice)
            await sendAudio(conn, audios)
        # æ¸…é™¤æœåŠ¡ç«¯è®²è¯çŠ¶æ€
        conn.clearSpeakStatus()

    # å‘é€æ¶ˆæ¯åˆ°å®¢æˆ·ç«¯
    await conn.websocket.send(json.dumps(message))


async def send_stt_message(conn, text):
    end_prompt_str = conn.config.get("end_prompt", {}).get("prompt")
    if end_prompt_str and end_prompt_str == text:
        await send_tts_message(conn, "start")
        return

    """å‘é€ STT çŠ¶æ€æ¶ˆæ¯"""
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯ ASR é”™è¯¯ï¼Œå¦‚æœæ˜¯åˆ™ä¸å‘é€æ¶ˆæ¯
    asr_error_indicators = [
        "æ£€æµ‹åˆ°ASRè¯†åˆ«å¯èƒ½å‡ºé”™",
        "å†…å®¹ä¸å®Œæ•´ä¸”æ— æ˜ç¡®æ„å›¾",
        "ä¿æŒé™é»˜ç­‰å¾…ç”¨æˆ·ç»§ç»­è¾“å…¥",
        "æ— æ³•ç†è§£æ‚¨çš„è¾“å…¥",
        "è¯·é‡æ–°è¯´ä¸€é"
    ]
    
    # æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å« ASR é”™è¯¯æŒ‡ç¤º
    is_asr_error = any(indicator in text for indicator in asr_error_indicators)
    
    # æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åªåŒ…å«æ— æ„ä¹‰çš„å­—ç¬¦ï¼ˆå¦‚"ê·¸"ã€"ä¹Ÿ"ç­‰å•å­—ï¼‰
    if len(text.strip()) <= 2 and not is_asr_error:
        is_asr_error = True
    
    if is_asr_error:
        conn.logger.bind(tag=TAG).info(f"æ£€æµ‹åˆ°ASRé”™è¯¯ï¼Œä¸å‘é€STTæ¶ˆæ¯: {text}")
        return
    
    # è§£æJSONæ ¼å¼ï¼Œæå–å®é™…çš„ç”¨æˆ·è¯´è¯å†…å®¹
    display_text = text
    try:
        # å°è¯•è§£æJSONæ ¼å¼
        if text.strip().startswith('{') and text.strip().endswith('}'):
            parsed_data = json.loads(text)
            if isinstance(parsed_data, dict) and "content" in parsed_data:
                # å¦‚æœæ˜¯åŒ…å«è¯´è¯äººä¿¡æ¯çš„JSONæ ¼å¼ï¼Œåªæ˜¾ç¤ºcontentéƒ¨åˆ†
                display_text = parsed_data["content"]
    except (json.JSONDecodeError, TypeError):
        # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ–‡æœ¬
        display_text = text
    
    stt_text = get_string_no_punctuation_or_emoji(display_text)
    await conn.websocket.send(
        json.dumps({"type": "stt", "text": stt_text, "session_id": conn.session_id})
    )
    conn.client_is_speaking = True
    await send_tts_message(conn, "start")
